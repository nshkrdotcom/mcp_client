Love this—these are exactly the calls we need to lock before touching code. Below is a **decisioned MVP spec** that answers each underspec with concrete choices, numbers, and edge behavior. It’s tight, minimal, and mechanically precise.

---

## MVP choices (final)

### 1) Tombstones: lifetime & correctness

**Decision:** **No fixed 60s.** Tombstones persist long enough to cover “late response after timeout + reconnect/backoff.”
**Rule:** `tombstone_ttl = request_timeout + init_timeout + backoff_max + 5_000` (ms).
**Why:** Covers worst-case: request times out, we immediately re-init (init_timeout), and we may sit at max backoff. The +5s epsilon absorbs jitter.
**Note:** Session-ID gating remains **post-MVP**. If you later add it, you can drop TTL to a small constant.

---

### 2) Frames during `:backoff`

**Decision:** **Do not buffer.**
On transition to `:backoff`, **tombstone all inflight ids** first (O(n)), then drop all incoming frames in `:backoff`.
**Why:** Predictable, bounded memory; no hidden queues. Least surprising for callers because every in-flight request deterministically fails, and any late response gets dropped via tombstones. (This is option **B**, not A/C.)

---

### 3) `:busy` handling (transport backpressure)

**Decision:** **Bounded inline retry inside the state machine** (cheap and avoids pushing complexity to callers).

* Attempts: **3** total (1 initial + 2 retries)
* Delay between retries: **10ms** with ±50% jitter
* If still busy: reply `{:error, %Error{kind: :transport, message: "backpressure"}}`
  **Why:** ~10 LOC, large usability win; still MVP-simple.

---

### 4) `max_frame_bytes`

**Decision:** Default **16_777_216 bytes (16MB)**.
If a single frame exceeds this, treat as **protocol error**: log, **close transport**, transition to `:backoff`. No negotiation in MVP.
**Why:** Sensible default that aligns with many JSON-RPC deployments; closing avoids running in degraded/undefined state.

---

### 5) Complete state table (MVP)

*All user calls in “not ready” states return the **struct** form: `{:error, %Error{kind: :state, message: "...", data: %{state: <state>}}}`.*

```
| Current        | Event                       | Guard/Notes                      | Action                                                         | Next         |
|----------------|-----------------------------|----------------------------------|----------------------------------------------------------------|--------------|
| :starting      | :spawn_ok                   |                                  | start init; arm init_timeout                                   | :initializing|
| :starting      | :spawn_error(reason)        |                                  | schedule backoff(1st); log reason                              | :backoff     |
| :starting      | user_call(_method, ...)     |                                  | reply {:error, %Error{kind: :state, data: %{state: :starting}}}| :starting    |

| :initializing  | init_response(ok,caps)      | valid caps                       | store caps; set session data;                                  | :ready       |
| :initializing  | init_response(error)        |                                  | log; schedule backoff                                          | :backoff     |
| :initializing  | init_timeout                 |                                  | schedule backoff                                               | :backoff     |
| :initializing  | transport_down(reason)      |                                  | schedule backoff                                               | :backoff     |
| :initializing  | frame(other)                |                                  | drop; set_active(:once)                                        | :initializing|
| :initializing  | user_call(...)              |                                  | reply {:error, %Error{kind: :state, data: %{state: :initializing}}}| :initializing|
| :initializing  | stop                        |                                  | close;                                                        | :closing     |

| :ready         | response(id)                | id in requests                   | deliver, clear timer/id, set_active(:once)                     | :ready       |
| :ready         | response(id)                | id not in requests; in tombstone | drop; set_active(:once)                                        | :ready       |
| :ready         | response(id)                | id unknown                       | warn & drop; set_active(:once)                                 | :ready       |
| :ready         | server_notification(cancelled_all) |                          | tombstone all inflight; clear requests; start init             | :initializing|
| :ready         | transport_down(reason)      |                                  | tombstone all inflight; clear requests; schedule backoff       | :backoff     |
| :ready         | user_call(method,params)    |                                  | make id; store row; send_frame with bounded retry; start timer | :ready       |
| :ready         | request_timeout(id)         |                                  | if present: reply timeout; send cancel; tombstone;             | :ready       |
| :ready         | stop                        |                                  | close;                                                        | :closing     |

| :backoff       | backoff_expire              |                                  | restart transport; start init                                  | :initializing|
| :backoff       | transport_up                |                                  | start init                                                     | :initializing|
| :backoff       | frame(_)                    |                                  | drop; (keep active disabled unless we test liveness)           | :backoff     |
| :backoff       | user_call(...)              |                                  | reply {:error, %Error{kind: :state, data: %{state: :backoff}}} | :backoff     |
| :backoff       | stop                        |                                  | close;                                                        | :closing     |

| :closing       | any                          |                                  | drop                                                           | :closing     |
```

*Notes:*

* “schedule backoff” = exponential with jitter, bounded by `backoff_max`.
* We don’t add `:re_syncing` in MVP; we perform tombstone+clear synchronously on the `:ready` edge before switching states.

---

### 6) Request tracking: map vs ETS

**Decision:** **Map** inside `Connection` for MVP.
**Why:** Less code, fewer moving parts; request volume in MVP is expected modest.
**Refactor path:** If/when a separate manager or cross-process inspection is needed, switch to `:protected` ETS owned by `Connection`. Migration is one module boundary.

---

### 7) Notifications: sync or async?

**Decision:** **Synchronous (MVP)**; **no TaskSupervisor**.

* We iterate handlers in-process; trap exceptions; log at warn.
* Document: “Handlers must be quick; slow handlers will delay the connection.”
  **Why:** Keeps supervision minimal and behavior explicit. We can add async dispatch post-MVP if needed.

---

### 8) Supervision/linking

**Decision:** **Use `rest_for_one` and do *not* add explicit links** between Connection and Transport in MVP.
**Why:** `rest_for_one` already guarantees that if Transport (first child) dies, children after it (Connection) restart. Simpler mental model, fewer signals to juggle.

Tree:

```
ConnectionSupervisor (rest_for_one)
  ├─ Transport (worker)
  └─ Connection (worker)   # started last
```

(We dropped TaskSupervisor for MVP per #7.)

---

### 9) Error shape (consistency)

**Decision:** Always return the **struct**:

```elixir
{:error, %Error{kind: :state, message: "client not ready", data: %{state: :backoff}}}
```

**Why:** Stable pattern-matching, room for context, consistent telemetry.

---

### 10) Property tests

**Decision:** **Include 3** properties in MVP:

1. **1:1 correlation** under reordering & unknown ids
2. **Timeouts don’t leak** (requests map empty; tombstones decay after `tombstone_ttl`)
3. **Cancellation idempotency** (N cancels → exactly one terminal outcome; no double replies)

They’re small and catch common footguns.

---

## Numeric defaults (commit)

```elixir
@defaults [
  request_timeout: 30_000,      # per-request
  init_timeout: 10_000,         # handshake
  backoff_min: 1_000,           # ms
  backoff_max: 30_000,          # ms (with jitter 0.2)
  max_frame_bytes: 16_777_216,  # 16MB
  retry_attempts: 3,            # send_frame busy retries (total)
  retry_delay_ms: 10,           # base delay; jitter ±50%
  tombstone_ttl: fn opts ->
    (opts[:request_timeout] || 30_000) +
    (opts[:init_timeout] || 10_000) +
    (opts[:backoff_max] || 30_000) +
    5_000
  end
]
```

---

## Answers to each “Critical underspecification”

1. **Tombstone TTL** → Covered with formula; rationale above.
2. **Dropping in `:backoff`** → We tombstone **before** leaving `:ready`, then drop; no buffering.
3. **`:busy` retry** → Inlined, bounded 3x inside state machine.
4. **max_frame_bytes** → 16MB default; violation closes connection and enters backoff.
5. **State edges** → Full table provided.
6. **Map vs ETS** → Map for MVP; ETS is refactor path.
7. **Task.Supervisor** → Out for MVP; synchronous handlers with guardrails.
8. **Linking vs strategy** → Rely on `rest_for_one`; no explicit links in MVP.
9. **Error shape** → Always `%Error{}`; include state in `data`.
10. **Properties** → Add cancellation idempotency now.

---

### One-line acceptance criteria summary

* One supervised connection (`rest_for_one`), no buffer queues, active-once transport, inline JSON decode, bounded send busy-retry, tombstones with formula TTL, strict error struct, and three property tests. Everything else is post-MVP.

If you want, I can turn this into a short `CONTRIBUTING.md#MVP-contract` and a `connection_state.md` with the table verbatim so contributors don’t re-litigate these choices.
